[32m2024-06-01 12:39:34.713[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m89[39m - [1m****************************************
[32m2024-06-01 12:39:34.714[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m90[39m - [1mStarting training with the arguments
[32m2024-06-01 12:39:34.714[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mmodel                          meta-llama/Llama-2-7b-hf
[32m2024-06-01 12:39:34.714[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mseed                           0
[32m2024-06-01 12:39:34.715[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mnsamples                       128
[32m2024-06-01 12:39:34.715[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mcache_dir                      /data/ajay_data/llama2_models
[32m2024-06-01 12:39:34.715[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1msave                           None
[32m2024-06-01 12:39:34.715[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1msave_model                     None
[32m2024-06-01 12:39:34.715[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mestimate_rank                  True
[32m2024-06-01 12:39:34.716[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mmodel_rank                     10
[32m2024-06-01 12:39:34.716[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mdata_dir                       ./data
[32m2024-06-01 12:39:34.716[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mntrain                         5
[32m2024-06-01 12:39:34.716[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mproject                        camera-ready-project
[32m2024-06-01 12:39:34.716[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mname                           adaptive-low-rank
[32m2024-06-01 12:39:34.716[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1msingular_value_path            ./data/singular_values_llama-2-13b.pt
[32m2024-06-01 12:39:34.717[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mmin_ratio                      0.0
[32m2024-06-01 12:39:34.717[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m92[39m - [1mrank_thresold                  0.0225
[32m2024-06-01 12:39:34.717[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m93[39m - [1m****************************************
[32m2024-06-01 12:39:34.719[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m101[39m - [1mloading llm model meta-llama/Llama-2-7b-hf
/home/aj32632/anaconda3/envs/mci/lib/python3.9/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(

Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                              | 1/2 [00:12<00:12, 12.31s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.35s/it]
[32m2024-06-01 12:39:54.685[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m104[39m -
[1mLlamaForCausalLM(
[1m  (model): LlamaModel(
[1m    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
[1m    (layers): ModuleList(
[1m      (0-31): 32 x LlamaDecoderLayer(
[1m        (self_attn): LlamaAttention(
[1m          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
[1m          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
[1m          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
[1m          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
[1m          (rotary_emb): LlamaRotaryEmbedding()
[1m        )
[1m        (mlp): LlamaMLP(
[1m          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
[1m          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
[1m          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
[1m          (act_fn): SiLUActivation()
[1m        )
[1m        (input_layernorm): LlamaRMSNorm()
[1m        (post_attention_layernorm): LlamaRMSNorm()
[1m      )
[1m    )
[1m    (norm): LlamaRMSNorm()
[1m  )
[1m  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
[1m)
[32m2024-06-01 12:39:54.687[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m105[39m - [1mTotal params: 6738.42M
[32m2024-06-01 12:39:54.688[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m106[39m - [1mTrainable params: 6738.42M
[32m2024-06-01 12:39:54.688[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m108[39m - [1mNamespace(model='meta-llama/Llama-2-7b-hf', seed=0, nsamples=128, cache_dir='/data/ajay_data/llama2_models', save=None, save_model=None, estimate_rank=True, model_rank=10, data_dir='./data', ntrain=5, project='camera-ready-project', name='adaptive-low-rank', singular_value_path='./data/singular_values_llama-2-13b.pt', min_ratio=0.0, rank_thresold=0.0225)
/home/aj32632/anaconda3/envs/mci/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
[32m2024-06-01 12:39:54.766[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m113[39m - [1mModel and tokenizer loaded
[32m2024-06-01 12:39:54.766[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m118[39m - [1muse device 
[32m2024-06-01 12:39:54.776[39m | [1mINFO    [22m | [36mlib.eval[39m:[36meval_ppl[39m:[36m23[39m - [1mEvaluating on c4 .....
[32m2024-06-01 12:39:56.466[39m | [1mINFO    [22m | [36mlib.eval[39m:[36meval_ppl_dataset[39m:[36m81[39m - [1mEvaluated samples: 0/149 || Throughput: 2430.008941312857 tokens/secs
[32m2024-06-01 12:40:25.797[39m | [1mINFO    [22m | [36mlib.eval[39m:[36meval_ppl_dataset[39m:[36m81[39m - [1mEvaluated samples: 20/149 || Throughput: 8090.077046562562 tokens/secs
[32m2024-06-01 12:40:55.251[39m | [1mINFO    [22m | [36mlib.eval[39m:[36meval_ppl_dataset[39m:[36m81[39m - [1mEvaluated samples: 40/149 || Throughput: 8051.728854325869 tokens/secs
[32m2024-06-01 12:41:24.796[39m | [1mINFO    [22m | [36mlib.eval[39m:[36meval_ppl_dataset[39m:[36m81[39m - [1mEvaluated samples: 60/149 || Throughput: 8033.5471813163895 tokens/secs
[32m2024-06-01 12:41:54.387[39m | [1mINFO    [22m | [36mlib.eval[39m:[36meval_ppl_dataset[39m:[36m81[39m - [1mEvaluated samples: 80/149 || Throughput: 8031.338908253175 tokens/secs
[32m2024-06-01 12:42:23.991[39m | [1mINFO    [22m | [36mlib.eval[39m:[36meval_ppl_dataset[39m:[36m81[39m - [1mEvaluated samples: 100/149 || Throughput: 8035.820566899183 tokens/secs
[32m2024-06-01 12:42:53.594[39m | [1mINFO    [22m | [36mlib.eval[39m:[36meval_ppl_dataset[39m:[36m81[39m - [1mEvaluated samples: 120/149 || Throughput: 8027.049767620279 tokens/secs
[32m2024-06-01 12:43:23.211[39m | [1mINFO    [22m | [36mlib.eval[39m:[36meval_ppl_dataset[39m:[36m81[39m - [1mEvaluated samples: 140/149 || Throughput: 8017.602076565416 tokens/secs
[32m2024-06-01 12:43:36.027[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m133[39m - [1mBefore Rank Reduction PPL on C4: 7.03898811340332
[32m2024-06-01 12:43:36.028[39m | [1mINFO    [22m | [36m__main__[39m:[36mmain[39m:[36m137[39m - [1mTotal params BEFORE Rank Reduction: 6738.42M
[32m2024-06-01 12:43:36.028[39m | [1mINFO    [22m | [36mutils[39m:[36madaptive_rank_pruning[39m:[36m122[39m - [1mUsing the mean threolding
[1msum(_data < args.rank_thresold = 0.0225)
[32m2024-06-01 12:43:36.346[39m | [1mINFO    [22m | [36mutils[39m:[36madaptive_rank_pruning[39m:[36m135[39m - [1mAttempted Rank Reduction: 9.648 %
[32m2024-06-01 12:43:36.347[39m | [1mINFO    [22m | [36mlib.rank_reduction[39m:[36mdo_rank_reduction[39m:[36m43[39m - [1m*************** Pruning Model Started ***************
Traceback (most recent call last):
  File "/home/aj32632/Camera_Ready/welore/welore_rank_reduction.py", line 159, in <module>
    main()
  File "/home/aj32632/Camera_Ready/welore/welore_rank_reduction.py", line 140, in main
    reduced_rank, total_rank = do_rank_reduction(args, model, tokenizer, rank_pruning, args.min_ratio, logger, False)
  File "/home/aj32632/Camera_Ready/welore/lib/rank_reduction.py", line 53, in do_rank_reduction
    if load_only is False:   l = LowRankLayer(k, module.weight.to(torch.float32), True)
  File "/home/aj32632/Camera_Ready/welore/lib/LowRankLayer.py", line 16, in __init__
    self.U = nn.Linear(desired_rank, U.shape[0], bias=False).to(weight.device)
  File "/home/aj32632/anaconda3/envs/mci/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 96, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -711: [4096, -711]
Traceback (most recent call last):
  File "/home/aj32632/Camera_Ready/welore/welore_rank_reduction.py", line 159, in <module>
    main()
  File "/home/aj32632/Camera_Ready/welore/welore_rank_reduction.py", line 140, in main
    reduced_rank, total_rank = do_rank_reduction(args, model, tokenizer, rank_pruning, args.min_ratio, logger, False)
  File "/home/aj32632/Camera_Ready/welore/lib/rank_reduction.py", line 53, in do_rank_reduction
    if load_only is False:   l = LowRankLayer(k, module.weight.to(torch.float32), True)
  File "/home/aj32632/Camera_Ready/welore/lib/LowRankLayer.py", line 16, in __init__
    self.U = nn.Linear(desired_rank, U.shape[0], bias=False).to(weight.device)
  File "/home/aj32632/anaconda3/envs/mci/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 96, in __init__
    self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))
RuntimeError: Trying to create tensor with negative dimension -711: [4096, -711]